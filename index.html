<!DOCTYPE html>
<html>
<head>
    <style>
        td,
        th {
            border: 0px solid black;
        }

        img {
            padding: 5px;
        }

        .content p {
            font-size: 16px; /* Adjust font size for paragraphs */
        }

        /* Custom style for the section causing the issue */
        .proposed-approach p {
            font-size: 16px; /* Smaller font size */
        }

        .proposed-approach h5 {
            font-size: 20px; /* Adjusted subtitle size */
        }

        /* Optionally adjust title sizes across the document */
        h2.title {
            font-size: 24px; /* Adjusted for all h2 elements */
        }
    </style>

    <title>AWRaCLe</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="shortcut icon" href="./static/images/jhu_web.png" />

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">
    <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title"> GenDeg: Diffusion-Based Degradation Synthesis for Generalizable All-in-One Image Restoration
                        </h1>
                        <div class="is-size-4 publication-authors">
                            <!-- Group of first four authors -->
                            <div class="authors-group">
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=SGty2eUAAAAJ&hl=en" target="_blank">Sudarshan Rajagopalan</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://nithin-gk.github.io/" target="_blank">Nithin Gopalakrishnan Nair</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://jayparanjape.github.io/website/" target="_blank">Jay N. Paranjape</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en"
                                        target="_blank">Vishal M. Patel</a>
                                </span>
                            </div>
                        </div>


                        <div class="is-size-4 publication-authors">
                            <span class="author-block">Johns Hopkins University</span>
                        </div>

                        <div class="column has-text-centered">
                            <a href="as"></a>
                            </span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
<div class="publication-links">
    <!-- PDF Link. -->
    <span class="link-block">
        <a href="https://drive.google.com/file/d/185XIpbF6wlCDCnV3J85Hlr6dMYRmAzC-/view?usp=sharing"
            class="external-link button is-normal is-rounded is-dark" target="_blank">
            <span class="icon">
                <i class="fas fa-file-pdf"></i>
            </span>
            <span>Paper</span>
        </a>
    </span>

    <!-- Supplementary material link commented out -->
    <!-- 
    <span class="link-block">
        <a href=""
            class="external-link button is-normal is-rounded is-dark" target="_blank">
            <span class="icon">
                <i class="fas fa-file-pdf"></i>
            </span>
            <span>Supplementary material</span>
        </a>
    </span>
    -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2409.00263"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>Arxiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href=""
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code (Coming Soon!)</span>
                                    </a>
                                </span>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <img src="./static/images/intro.png" alt="" style="border:0; height:500px; width:1500px;">
                        <div class="content has-text-justified">
                        <p>
                          
                        </p>
                        </div>
                    <h2 class="title is-3">Abstract</h2>
                    
                    <div class="content has-text-justified">
                        <p>
                            Deep learningâ€“based models for All-In-One image Restoration (AIOR) have achieved significant advancements in recent years. 
                            However, their practical applicability is limited by poor generalization to samples outside the training distribution. 
                            This limitation arises primarily from insufficient diversity in degradation variations and scenes within existing datasets, 
                            resulting in inadequate representations of real-world scenarios. 
                            Additionally, capturing large-scale real-world paired data for degradations such as haze, low-light, and raindrops is often cumbersome and sometimes infeasible. 
                            In this paper, we leverage the generative capabilities of latent diffusion models to synthesize high-quality degraded images from their clean counterparts. 
                            Specifically, we introduce GenDeg, a degradation and intensity-aware conditional diffusion model, capable of producing diverse degradation patterns on clean images. 
                            Using GenDeg, we synthesize over 550k samples across six degradation types: haze, rain, snow, motion blur, low-light, and raindrops. 
                            These generated samples are integrated with existing datasets to form the GenDS dataset, comprising over 750k samples. 
                            Our experiments reveal that image restoration models trained on GenDS dataset exhibit significant improvements in out-of-distribution 
                            performance as compared to when trained solely on existing datasets. 
                            Furthermore, we provide comprehensive analyses on implications of diffusion model-based synthetic degradations for AIOR.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Paper video. -->

            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Proposed Approach</h2>
                            <div class="content has-text-justified proposed-approach">
                                <h5 class="subtitle has-text-centered"></h5>

                                <img src="./static/images/block.png" alt="" border=0 height=500 width=1500></img></
                                <p>
                                    Illustration of our GenDeg framework: (a) Describes the training stage of our pipeline. (b) Shows the inference process for degradation generation. (c) Depicts the architecture of 
                                    our Swin transformer-based restoration model.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Results and Comparison</h2>
                            <div class="content has-text-justified proposed-approach">
                                <h5 class="subtitle has-text-centered"></h5>
                                <img src="./static/images/table.png" alt="" border="0" height="500" width="1500">
                                <p> Quantitative comparisons of AWRaCLe with state-of-the-art approaches on all-weather image restoration benchmarks. AWRaCLe achieves a significant improvement in performance
                                over SOTA.</p>
                                <img src="./static/images/qual.png" alt="" border="0" height="500" width="1500">
                                <p>
                                    Qualitative comparisons of AWRaCLe with state-of-the-art-approaches for dehazing, desnowing and deraining tasks.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <!--/ Paper video. -->

        </div>
    </section>

    <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Analysis</h2>
                            <div class="content has-text-justified proposed-approach">
                                <h5 class="subtitle has-text-centered"></h5>
                                <img src="./static/images/dce.png" alt="" border="0" height="500" width="1500">
                                <p> DCE block activations overlayed on the degraded and clean image of the context pair. The DCE blocks capture attributes of degradations such
                                    as the spatially varying characteristics of haze and sparseness of snow. Yellow-High, Blue-Low</p>
                                <img src="./static/images/tsne.png" alt="" border="0" height="500" width="1500">
                                <p>
                                    t-SNE plot of DCE block outputs for hazy, rainy and snowy context pairs. The clusters are well separated.
                                </p>
                                
                                <img src="./static/images/cf.png" alt="" border="0" height="500" width="1500">
                                <p>
                                    Comparison of activations of the restoration network prior to CF and after CF. After CF, the degradation information in the activation is significantly enhanced.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <!--/ Paper video. -->

        </div>
    </section>

    <section class="section" id="BibTeX">
                <div class="container content is-max-desktop">
                    <h2 class="title">BibTeX</h2>
                    <pre><code>@article{rajagopalan2024awracle,
      title={AWRaCLe: All-Weather Image Restoration using Visual In-Context Learning}, 
      author={Sudarshan Rajagopalan and Vishal M. Patel},
      year={2024},
      eprint={2409.00263},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.00263}, 
}
</code></pre>
                </div>
            </section>

            <section class="section">
                <div class="container is-max-desktop content">
                    <h5 class="title" style="font-size: 10px;"> Acknowledgement: The website template is taken from
                        <span class="author-block">
                            <a href="https://nerfies.github.io/" target="_blank">Nerfies</a>
                    </h5>

                </div>
            </section>

            <script>
                const viewers = document.querySelectorAll(".image-compare");
                viewers.forEach((element) => {
                    let view = new ImageCompare(element, {
                        hoverStart: true,
                        addCircle: true
                    }).mount();
                });

                $(document).ready(function () {
                    var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
                        lineNumbers: false,
                        lineWrapping: true,
                        readOnly: true
                    });
                    $(function () {
                        $('[data-toggle="tooltip"]').tooltip()
                    })
                });
            </script>
</body>

</html>
